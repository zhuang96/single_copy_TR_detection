{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Log:</b> \n",
    "<p>\n",
    "<list>\n",
    "<li>Created own environment on SCC\n",
    "<li>Downloaded Varsim \n",
    "<li>After trying to run Varsim and configring all other necessary files/tools; bug appeared (Logger...no 'write' attribute)\n",
    "<li>BUG; issue opened and fixed on GitHub\n",
    "<li>New BUG (Exception:Aborting...please check log)\n",
    "<li>Extracted and compressed my Varsim log files to .tar.gz and posted on Issue thread on GitHub (<i>waiting for response</i>)\n",
    "<li>Requested and gained access to TRDB\n",
    "<li>Downloaded Homo Sapien HG38 Chromosome 11 .seq file \n",
    "<li> 2/15/18 Notified that Varsim bug is being worked on\n",
    "<li> created Python code to read and separate Genome/Chr txt files and shorten them as well\n",
    "<li> however, having issues reading the .fa file and extracting the whole desired string to work with \n",
    "<li> python able to read .fa file, but it is based 1, which means I must shift "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is pseudo-code I have in mind for appraoching this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import reference string as ref_string\n",
    "#import TRDB info as info_input\n",
    "import collections\n",
    "\n",
    "dictionary={}\n",
    "ordered_dictionary={}\n",
    "\n",
    "def reading_info():\n",
    "    #skip first line, then\n",
    "    first_ind=info_input[0]\n",
    "    last_ind=info_input[1]\n",
    "    pattern_size=info_input[2]\n",
    "    copy_num=info_input[3]\n",
    "    arr_len=info_input[4]\n",
    "\n",
    "    #first copy\n",
    "    single_copy=ref_string[first_ind:pattern_size]\n",
    "    #remaining bits (if any)\n",
    "    remainder_ind=first_ind+(pattern_size*(copy_num/1)) #rounds copy_num down \n",
    "    single_copy.append(ref_string[remainder_ind:(last_ind+1)])\n",
    "\n",
    "    #add to dictionary\n",
    "    dictionary[first_index]=(single_copy,last_ind)\n",
    "\n",
    "def sortDictionary():\n",
    "    ordered_dictionary = collections.OrderedDict(sorted(dictionary.items()))\n",
    "    return ordered_dictionary\n",
    "    \n",
    "def create_new_seq():\n",
    "    #new string with <1.9 copies\n",
    "    new_ref=\"\"\n",
    "    #tracker of starting index\n",
    "    cur_ind=0\n",
    "    #go through oredered_dictionary to append flanking left seq and TR single copy sequence\n",
    "    for i in range(len(ordered_dictionary)):\n",
    "        cur_ind=ordered_dictionary.key()[i]\n",
    "        new_ref.append(ref_string[start_ind]:cur_ind)\n",
    "        new_ref.append(ordered_dictionary.value()[i][0])\n",
    "        start_ind=ordered_dictionary.value()[i][1]\n",
    "    #append last chunk of string after last detected TR\n",
    "    return new_ref.append(ref_string[start_ind:])\n",
    "    \n",
    "def main():\n",
    "    with open(input_file) as f:\n",
    "        #skip first line, then do\n",
    "        for line in f:\n",
    "            reading_info(line.split(,))\n",
    "    sortDictionary()\n",
    "    create_new_seq()\n",
    "    \n",
    "    #export as ASCII file? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally used a dictionary but then realized storing a list in a list was not complicated; switched over to that (since dictionary is not sorted)...\n",
    "\n",
    "<p>Currently having lots of trouble with reading a .fa file; downloaded multiple fasta readers but they don't work (either not enough storage to read or extremely laggy and does not load). Therefore, am having trouble reading the whole desired sequence to edit the shorted TRs into. *Python doesn't read the .fa file properly* </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2/25/18) UPDATE: Was able to create a bed file with the chromosome file I have been tested on. Right now I still need to run it through BWA. But before that I have some questions about my code: <br>\n",
    "\n",
    "<ul>\n",
    "<li>Are the indexes for the chromosome correct?? I am assuming NO! This might only be an issue when working with more than one chromosome in the same file.....\n",
    "<li>Since BED files are Based 0, I need to subtract 1 since the TRDB files are based 1. But if the starting index is 0...where does the BED index start? Do we lose an index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global variables\n",
    "ref_list=[]\n",
    "\n",
    "def reading_info(info_input):\n",
    "    \n",
    "    first_ind=int(info_input[0])\n",
    "    last_ind=int(info_input[1])\n",
    "    pattern_size=int(info_input[2])\n",
    "    copy_num=float(info_input[3])\n",
    "    pattern=info_input[5]\n",
    "    arr_seq=info_input[6]\n",
    "    \n",
    "    #get remainder\n",
    "    remainder_len=int((copy_num-(copy_num//1))*pattern_size)//1\n",
    "    remainder_str=arr_seq[:remainder_len]\n",
    "    \n",
    "    #concat remainder to pattern\n",
    "    single_copy=pattern+remainder_str\n",
    "\n",
    "    #add to dictionary\n",
    "    ref_list.append([first_ind,single_copy,last_ind])    \n",
    "\n",
    "def create_new_seq(ref_string):\n",
    "    new_ref=\"\"\n",
    "    #tracker of starting index\n",
    "    start_ind=0\n",
    "    \n",
    "    #go through oredered_dictionary to append flanking left seq and TR single copy sequence\n",
    "    for i in range(len(ref_list)):\n",
    "        cur_ind=ref_list[i][0]\n",
    "        #append sequence w/o TR\n",
    "        new_ref+=(ref_string[start_ind:cur_ind])\n",
    "        #append shortened TR copy\n",
    "        new_ref+=ref_list[i][1]\n",
    "        #start again at end index\n",
    "        start_ind=ref_list[i][2]\n",
    "        \n",
    "    #append last chunk of string after last detected TR\n",
    "    new_ref+=(ref_string[start_ind:])\n",
    "    return new_ref\n",
    "    \n",
    "def main():\n",
    "    #open TRDB file\n",
    "    with open('/Users/Zoe/Desktop/SPRING18/TANDEMREPEATS/Human Chr. 21.txt') as f:\n",
    "        #skip first line, then do\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            reading_info(line.split(\",\"))\n",
    "    #open ref seq file \n",
    "    with open(\"/Users/Zoe/Desktop/SPRING18/TANDEMREPEATS/chr21.fa\") as dat:\n",
    "        #skip first line\n",
    "        next(dat)\n",
    "        #since the file is based 0, must add a white space char\n",
    "        ref_nowhitespace=\" \"\n",
    "        for line in dat:\n",
    "            #remove all whitespace\n",
    "            ref_nowhitespace += line.strip() \n",
    "            \n",
    "#make whole sequence UPPERCASE\n",
    "    ref_nowhitespace=ref_nowhitespace.upper()\n",
    "\n",
    "#testing ; add one because also want the last index\n",
    "#    print ref_nowhitespace[5010564:5010609+1]\n",
    "#    print ref_nowhitespace[46699842:46699983+1]\n",
    "#    print ref_nowhitespace[46506725:46506819+1]\n",
    "\n",
    "    new_ref_string=create_new_seq(ref_nowhitespace)\n",
    "    print new_ref_string\n",
    "\n",
    "#TRDB is based 1    \n",
    "#need to create import numpy as np\n",
    "import xlwt\n",
    "from pandas import DataFrame\n",
    "\n",
    "#global variables\n",
    "ref_list=[]\n",
    "\n",
    "fasta_list=[]\n",
    "chrstart_list=[]\n",
    "chrend_list=[]\n",
    "\n",
    "def reading_info(info_input):\n",
    "    \n",
    "    first_ind=int(info_input[0])\n",
    "    last_ind=int(info_input[1])\n",
    "    pattern_size=int(info_input[2])\n",
    "    copy_num=float(info_input[3])\n",
    "    # pattern=info_input[4]\n",
    "    arr_seq=info_input[5]\n",
    "    fasta_header=info_input[4]\n",
    "    \n",
    "    final_len= pattern_size*(copy_num - (trunc(copy_num-1.8)+1))\n",
    "\n",
    "    single_copy=arr_seq[:int(round(final_len))]\n",
    "\n",
    "    ref_list.append([first_ind,single_copy,last_ind,fasta_header]) \n",
    "    # ref_list.append([first_ind,single_copy,last_ind])    \n",
    "\n",
    "def trunc(x):\n",
    "    if (x<1):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.floor(x)\n",
    "    \n",
    "def create_new_seq(ref_string):\n",
    "    new_ref=\"\"\n",
    "    #tracker of starting index\n",
    "    start_ind=0\n",
    "    \n",
    "    fasta_list.append([ref_list[0][-1]])\n",
    "    chrstart_list.append([start_ind])\n",
    "\n",
    "    #go through oredered_dictionary to append flanking left seq and TR single copy sequence\n",
    "    for i in range(len(ref_list)):\n",
    "        if ([ref_list[i][-1]] not in fasta_list):\n",
    "            print ref_list[i][-1]\n",
    "            fasta_list.append([ref_list[0][-1]])\n",
    "            chrstart_list.append([start_ind-1])\n",
    "            chrend_list.append(len(new_ref)-1)\n",
    "\n",
    "        cur_ind=ref_list[i][0]\n",
    "        #append sequence w/o TR\n",
    "        new_ref+=(ref_string[start_ind:cur_ind])\n",
    "        #append shortened TR copy\n",
    "        new_ref+=ref_list[i][1]\n",
    "        #start again at end index\n",
    "        start_ind=ref_list[i][2]\n",
    "        \n",
    "    #append last chunk of string after last detected TR\n",
    "    new_ref+=(ref_string[start_ind:])\n",
    "\n",
    "    chrend_list.append([len(new_ref)-1])\n",
    "\n",
    "    return new_ref\n",
    "    \n",
    "#def main():\n",
    "#open TRDB file\n",
    "with open('/Users/Zoe/Desktop/SPRING18/TANDEMREPEATS/Human Chr. 21.txt') as f:\n",
    "    #skip first line, then do\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        reading_info(line.split(\",\"))\n",
    "#open ref seq file \n",
    "with open(\"/Users/Zoe/Desktop/SPRING18/TANDEMREPEATS/chr21.fa\") as dat:\n",
    "    #skip first line\n",
    "    next(dat)\n",
    "    #since the file is based 0, must add a white space char\n",
    "    ref_nowhitespace=\" \"\n",
    "    for line in dat:\n",
    "        #remove all whitespace\n",
    "        ref_nowhitespace += line.strip() \n",
    "        \n",
    "#make whole sequence UPPERCASE\n",
    "ref_nowhitespace=ref_nowhitespace.upper()\n",
    "\n",
    "#testing ; add one because also want the last index\n",
    "# print ref_nowhitespace[5010564:5010609+1]\n",
    "#    print ref_nowhitespace[46699842:46699983+1]\n",
    "#    print ref_nowhitespace[46506725:46506819+1]\n",
    "\n",
    "new_ref_string=create_new_seq(ref_nowhitespace)\n",
    "\n",
    "# print new_ref_string[5010564+2454:5010564+2454+35]\n",
    "# print ref_list[1]\n",
    "# print ref_list[-8]\n",
    "# print len(ref_list[-8][1])\n",
    "\n",
    "# fasta_list.append(ref_list[0][-1])\n",
    "# chrstart_list.append([0])\n",
    "# chrend_list.append([len(new_ref_string)-1])\n",
    "# df = DataFrame({'Chr End': chrend_list, 'Chr Start': chrstart_list,'FASTA Header': fasta_list})\n",
    "# df.to_excel('.txt', sheet_name='sheet1', index=False)\n",
    "\n",
    "\n",
    "# print len (fasta_list)\n",
    "\n",
    "f= open(\"newbed.bed\",\"w+\")\n",
    "for i in range(len (fasta_list)):\n",
    "    f.write(str(fasta_list[i][0])+\"\\t\"+str(chrstart_list[i][0])+\"\\t\"+str(chrend_list[i][0])+\"\\t\")\n",
    "# f.write(str(fasta_list)+\"\\t\"+str(chrstart_list)+\"\\t\"+str(chrend_list)+\"\\t\")\n",
    "f.close() \n",
    "\n",
    "#TRDB is based 1    \n",
    "#need to create BED file if new indexes of first index's    \n",
    "#export as ASCII file? BED file if new indexes of first index's    \n",
    "#export as ASCII file? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the command for Varsim (will vary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "./varsim-master/varsim.py --vc_in_vcf All.20170710.vcf.gz --sv_insert_seq insert_seq.txt \\\n",
    "--sv_dgv GRCh38_hg38_supportingvariants_2016-08-31.txt \\\n",
    "--reference /project/vntrseek/share/GRCh38/GRCh38.fa  --id test --read_length 100 --vc_num_snp 3000000 --vc_num_ins 100000 \\\n",
    "--vc_num_del 10 --vc_num_mnp 10 --vc_num_complex 10 --sv_num_ins 10 \\\n",
    "--sv_num_del 100 --sv_num_dup 200 --sv_num_inv 1000 --sv_percent_novel 0.01 \\\n",
    "--vc_percent_novel 0.00 --mean_fragment_size 350 --sd_fragment_size 50 \\\n",
    "--vc_min_length_lim 10 --vc_max_length_lim 49 --sv_min_length_lim 50 \\\n",
    "--sv_max_length_lim 1000000 --nlanes 1 --total_coverage 1 \\\n",
    "--simulator_executable ART/art_bin_MountRainier/art_illumina --out_dir out --log_dir log --work_dir work \\\n",
    "--simulator art "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Below are the parameters for using BWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Use BWA aln to map the read data to human chromosome 1\n",
    "\n",
    "Parameters are as follows:\n",
    "\n",
    "-n maximum number of differences allowed between the read and the mapped location, here, 4% of the read length (default is 0.04)\n",
    "-o maximum number of gap starts allowed (default is 1)\n",
    "-e maximum number of gap extensions allowed (default is -1 means single character gaps)\n",
    "-t number of threads (perhaps set to number of processor cores)\n",
    "files\n",
    "chr1.fa – reference fasta file\n",
    "yanhuang_PE1.fq.gz – read data file in gzipped fastq format\n",
    "outyh1.sai – output file (sai means suffix array indices)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "bedtools\n",
    "\n",
    "0 based rather than 1 *saved bedfile should be one less\n",
    "\n",
    "FIRST 3 REQUIRED BED FIELDS:\n",
    "    chrom name (fasta header)\n",
    "    chromStart (first_ind -1) \n",
    "    chromEnd (last_ind -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2/27/18\n",
    "Installed bedtools; installed BWA\n",
    "\n",
    "need to create genome file and fasta file to run through BWA program\n",
    "\n",
    "~is there a difference between fa and fasta file? \n",
    "~what is a fastq; whatis the difference between a fastq and a fasta file? \n",
    "\n",
    "I think i can just export the new sequences as a .fa through my python program but should double check\n",
    "\n",
    "GENOME FILE has TWO COLUMNS : (chr num ,\"\\t\" END_coordinate)\n",
    "    the end coordinate is the last index; based 0 or 1? \n",
    "    .ga\n",
    "    https://biostar.usegalaxy.org/p/17006/ \n",
    "                               \n",
    "*create .fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/14 : \n",
    "    Have the reads for chr 21 and chr 21 fasta file. \n",
    "    How to start BWA program? \"make\"\n",
    "    \n",
    "    steps:\n",
    "        !bwa index -a is chr1.fa\n",
    "        !bwa aln -n 0.04 -o 2 -e -1 -t 1 chr21.fa chr21_feed.fa > outchr21maps.sai\n",
    "        ...\n",
    "   \n",
    "    need reads from Marzie\n",
    "    \n",
    "    transferring all files to scc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#global variables\n",
    "ref_list=[]\n",
    "\n",
    "fasta_list=[]\n",
    "chrstart_list=[]\n",
    "chrend_list=[]\n",
    "check_tr=[]\n",
    "\n",
    "\n",
    "#truncate and add to ref_list the FIRST_INDEX, NEW_COPY, LAST_INDEX, FASTA_HEADER\n",
    "def reading_info(info_input):\n",
    "    \n",
    "    first_ind=int(info_input[0])\n",
    "    last_ind=int(info_input[1])\n",
    "    pattern_size=int(info_input[2])\n",
    "    copy_num=float(info_input[3])\n",
    "    fasta_header=info_input[5]\n",
    "    arr_seq=info_input[6]\n",
    "    \n",
    "    final_len= pattern_size*(copy_num - (trunc(copy_num-1.8)+1))\n",
    "\n",
    "    single_copy=arr_seq[:int(round(final_len))]\n",
    "\n",
    "    ref_list.append([first_ind,single_copy,last_ind,fasta_header]) \n",
    "\n",
    "def trunc(x):\n",
    "    if (x<1):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.floor(x)\n",
    "    \n",
    "def create_new_seq(ref_string):\n",
    "    new_ref=\"\"\n",
    "    #tracker of starting index\n",
    "    start_ind=0\n",
    "    \n",
    "    # fasta_list.append([ref_list[0][-1]])\n",
    "    # chrstart_list.append([start_ind]) #wrong \n",
    "\n",
    "    #go through oredered_dictionary to append flanking left seq and TR single copy sequence\n",
    "    for i in range(len(ref_list)):\n",
    "        # if ([ref_list[i][-1]] not in fasta_list):\n",
    "        #     #print ref_list[i][-1]\n",
    "        #     fasta_list.append([ref_list[0][-1]])\n",
    "        #     chrstart_list.append([start_ind-1])\n",
    "        #     chrend_list.append(len(new_ref)-1)\n",
    "\n",
    "        # print(ref_string[start_ind:cur_ind])\n",
    "        # print(\"start_ind is \" + str(start_ind) + \" cur_ind is \" + str(cur_ind))\n",
    "        # if(i==2):\n",
    "        # \tbreak;\n",
    "\n",
    "\n",
    "        fasta_list.append([ref_list[i][-1]])\n",
    "        #start of TR \n",
    "        cur_ind=ref_list[i][0]\n",
    "        #append sequence w/o TR\n",
    "        new_ref+=(ref_string[start_ind:cur_ind])\n",
    "        #start of TR is len(new_ref) b/c +1 -1 prior start index\n",
    "        chrstart_list.append([len(new_ref)])\n",
    "        #append shortened TR copy\n",
    "        new_ref+=ref_list[i][1]\n",
    "        #end of TR is len(new_ref)-1\n",
    "        chrend_list.append([len(new_ref)-1])\n",
    "        #double check TR indexes\n",
    "        check_tr.append(new_ref[chrstart_list[i][0]:chrend_list[i][0]+1])\n",
    "        #start again at end index\n",
    "        start_ind=ref_list[i][2]\n",
    "        \n",
    "    #append last chunk of string after last detected TR\n",
    "    new_ref+=(ref_string[start_ind:])\n",
    "\n",
    "    # chrend_list.append([len(new_ref)-1])\n",
    "\n",
    "    return new_ref\n",
    "    \n",
    "#def main():\n",
    "#open TRDB file\n",
    "with open('/Users/Zoe/Desktop/SPRING18/EXTRA_CIR/TANDEMREPEATS/ref_set_chr21.txt') as f:\n",
    "    #skip first line, then do\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        reading_info(line.split(\"\\t\"))\n",
    "#open ref seq file \n",
    "with open(\"/Users/Zoe/Desktop/SPRING18/EXTRA_CIR/TANDEMREPEATS/chr21.fa\") as dat:\n",
    "    #skip first line\n",
    "    next(dat)\n",
    "    #since the file is based 0, must add a white space char\n",
    "    ref_nowhitespace=\" \"\n",
    "    for line in dat:\n",
    "        #remove all whitespace\n",
    "        ref_nowhitespace += line.strip() \n",
    "        \n",
    "#make whole sequence UPPERCASE\n",
    "ref_nowhitespace=ref_nowhitespace.upper()\n",
    "\n",
    "\n",
    "create_modified_chr21=open(\"modified_chr21.txt\",\"w+\")\n",
    "create_modified_chr21.write(ref_nowhitespace)\n",
    "create_modified_chr21.close()\n",
    "\n",
    "#testing ; add one because also want the last index\n",
    "# print ref_nowhitespace[5010564:5010609+1]\n",
    "#    print ref_nowhitespace[46699842:46699983+1]\n",
    "#    print ref_nowhitespace[46506725:46506819+1]\n",
    "\n",
    "new_ref_string=create_new_seq(ref_nowhitespace)\n",
    "\n",
    "################################TESTING####################################\n",
    "\n",
    "# for i in range(len(ref_list)):\n",
    "# \tprint str(ref_list[i])\n",
    "# print new_ref_string[5010564+2454:5010564+2454+35]\n",
    "# print ref_list[1]\n",
    "# print ref_list[-8]\n",
    "# print len(ref_list[-8][1])\n",
    "\n",
    "\n",
    "################################CREATING FILES####################################\n",
    "#double checking \n",
    "dc=open(\"chr21_feed.fa\",\"w+\")\n",
    "for i in range(len (fasta_list)):\n",
    "\t# dc.write(str(fasta_list[i][0])+\"\\t\"+str(chrstart_list[i][0]-1)+\"\\t\"+str(chrend_list[i][0]-1)+\"\\n\")\n",
    "    dc.write(str(fasta_list[i][0])+\"\\t\"+str(chrstart_list[i][0])+\"\\t\"+str(chrend_list[i][0])+\"\\t\"+str(check_tr[i])+\"\\t\"+str(ref_list[i][1]+\"\\n\"))\n",
    "dc.close() \n",
    "\n",
    "checkthis=open(\"checkthis.txt\",\"w+\")\n",
    "sindex=45787976\n",
    "for i in range(4036,4041):\n",
    "\tcheckthis.write(\"prior: \"+ str(new_ref_string[sindex:chrstart_list[i][0]]+\"\\n\"+\"compare to: \"+str(ref_list[i])))\n",
    "\tsindex=chrstart_list[i][0]\n",
    "checkthis.close()\n",
    "#create genome file\n",
    "# g=open(\"chr21_new.genome\",\"w+\")\n",
    "# for i in range(len (fasta_list)):\n",
    "#     g.write(str(fasta_list[i][0])+\"\\t\"+str(chrend_list[i][0])+\"\\t\")\n",
    "# g.close() \n",
    "\n",
    "# print len (fasta_list)\n",
    "\n",
    "#create wraparound of new string\n",
    "# wraparound= open(\"chr21_new_wraparound.txt\",\"w+\")\n",
    "# wraparound.write(new_ref_string)\n",
    "# wraparound.close() \n",
    "\n",
    "#create wraparound of old string\n",
    "wraparound= open(\"chr21_wraparound.txt\",\"w+\")\n",
    "wraparound.write(ref_nowhitespace)\n",
    "wraparound.close() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bwa aln -n 0.04 -o 2 -e -1 -t 8 chr21_new_wraparound.fa /projectnb/vntrseek/CHM1/new_data/100bp/fastq_SRR1514952_1.fastq.gz > bwa_aln_chr21_1.sai\n",
    "\n",
    "bwa aln -n 0.04 -o 2 -e -1 -t 8 chr21_new_wraparound.fa /projectnb/vntrseek/CHM1/new_data/100bp/fastq_SRR1514952_2.fastq.gz > bwa_aln_chr21_2.sai\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
